name: "Obs Summary & Artifact"
description: "Aggregate job metrics, write step summary, and upload observability.json"
author: "a5c.ai"
runs:
  using: "composite"
  steps:
    - name: Collect metrics and write summary + file
      id: collect
      shell: bash
      run: |
        set -euo pipefail
        # Defaults (prefer shell defaults over expressions for portability)
        OBS_FILE="${OBS_FILE:-observability.json}"
        JOB_NAME="${JOB_NAME:-${GITHUB_JOB:-}}"
        WORKFLOW_NAME="${WORKFLOW_NAME:-${GITHUB_WORKFLOW:-}}"
        RUN_ID="${RUN_ID:-${GITHUB_RUN_ID:-}}"
        RUN_ATTEMPT="${RUN_ATTEMPT:-${GITHUB_RUN_ATTEMPT:-1}}"
        REPO="${REPO:-${GITHUB_REPOSITORY:-}}"
        SHA="${SHA:-${GITHUB_SHA:-}}"
        BRANCH_REF="${BRANCH_REF:-${GITHUB_REF:-}}"
        CONCLUSION="${CONCLUSION:-}"
        # Optional: caller can pass the workflow run start time; else we'll fallback
        RUN_STARTED_AT="${RUN_STARTED_AT:-}"

        echo "OBS_FILE=${OBS_FILE}" >> "$GITHUB_ENV"

 
        # Compose JSON (includes coverage, cache metrics, started_at/duration, and vitest tests)
        node "${GITHUB_ACTION_PATH:-.github/actions/obs-summary}/compose.cjs" > "$OBS_FILE"

        # Optional schema validation (warn-only)
        if [ "${OBS_VALIDATE_SCHEMA:-false}" = "true" ]; then
          echo "Validating $OBS_FILE against docs/specs/observability.schema.json (warn-only)" >> "$GITHUB_STEP_SUMMARY"
          node -e '
            try {
              const fs = require("fs");
              // Use Ajv 2020 to support Draft 2020-12 meta-schema referenced by our schema
              const Ajv2020 = require("ajv/dist/2020");
              const addFormats = require("ajv-formats");
              const schema = JSON.parse(fs.readFileSync("docs/specs/observability.schema.json", "utf8"));
              const data = JSON.parse(fs.readFileSync(process.env.OBS_FILE, "utf8"));
              const ajv = new Ajv2020({ strict: true, allErrors: true });
              addFormats(ajv);
              const validate = ajv.compile(schema);
              const ok = validate(data);
              if (!ok) {
                console.log("Schema validation warnings:", validate.errors);
                process.exitCode = 0;
              } else {
                console.log("Schema validation passed.");
              }
            } catch (e) {
              console.log("Schema validation encountered an error (ignored):", e && e.message);
              process.exitCode = 0;
            }
          '
        fi
 
        # Compose JSON (includes coverage, cache metrics, started_at/duration, and vitest tests)
        # Using compose.cjs keeps schema compatibility and logic centralized.
        # OBS_FILE is written by compose.cjs
        :


        echo "## Observability" >> "$GITHUB_STEP_SUMMARY"
        echo "- Repo: ${REPO}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Workflow: ${WORKFLOW_NAME}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Job: ${JOB_NAME}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Run: ${RUN_ID} (attempt ${RUN_ATTEMPT})" >> "$GITHUB_STEP_SUMMARY"
        # Optional conclusion line
        if [ -n "${CONCLUSION}" ]; then
          echo "- Conclusion: ${CONCLUSION}" >> "$GITHUB_STEP_SUMMARY"
        fi
        if [ -f coverage/coverage-summary.json ]; then
          LINES=$(node -e "const s=require('fs').readFileSync('coverage/coverage-summary.json','utf8'); const t=JSON.parse(s).total||{}; console.log((t.lines?.pct??0).toFixed(2))")
          FUNCS=$(node -e "const s=require('fs').readFileSync('coverage/coverage-summary.json','utf8'); const t=JSON.parse(s).total||{}; console.log((t.functions?.pct??0).toFixed(2))")
          BRANCHES=$(node -e "const s=require('fs').readFileSync('coverage/coverage-summary.json','utf8'); const t=JSON.parse(s).total||{}; console.log((t.branches?.pct??0).toFixed(2))")
          echo "- Coverage: lines ${LINES}% | funcs ${FUNCS}% | branches ${BRANCHES}%" >> "$GITHUB_STEP_SUMMARY"
        fi
        # Duration line (if computable)
        DUR=$(node -e "try{const o=JSON.parse(require('fs').readFileSync(process.env.OBS_FILE,'utf8')); if(o?.run?.duration_ms!=null){ console.log(o.run.duration_ms) }}catch{}") || true
        if [ -n "${DUR}" ]; then
          echo "- Duration: ${DUR} ms" >> "$GITHUB_STEP_SUMMARY"
        fi
 
        # If vitest JSON exists, append flaky/slow summary
        if [ -f vitest-results.json ]; then
          node -e '
            const fs = require("fs");
            const s = fs.readFileSync("vitest-results.json","utf8");
            const v = JSON.parse(s);
            const all = [];
            for (const tr of (v.testResults||[])) {
              for (const a of (tr.assertionResults||[])) {
                const meta = a.meta || {};
                const attempts = Number(meta.retryCount || meta.retries || 0);
                all.push({ n: a.fullName || a.title || "", d: a.duration ?? null, r: attempts });
              }
            }
            const flaky = all.filter(t => (t.r||0) > 0).length;
            const slowest = all.filter(t => typeof t.d === "number").sort((a,b)=> (b.d||0)-(a.d||0)).slice(0,5);
            let out = "\n### Tests (from vitest JSON)\n";
            out += `- Flaky suspects (retries>0): ${flaky}\n`;
            if (slowest.length) {
              out += "- Slowest tests:\n";
              for (const t of slowest) out += `  - ${t.n} â€” ${t.d} ms\n`;
            }
            fs.appendFileSync(process.env.GITHUB_STEP_SUMMARY, out);
          ';
        fi
        # Cache summary if envs provided
        kinds=$(env | awk -F= '/^CACHE_[A-Z0-9]+_HIT=/{print $1}' | sed -E 's/^CACHE_([A-Z0-9]+)_HIT.*/\1/; s/.*/\L&/')
        if [ -n "${kinds}" ]; then
          hits=0; total=0; bytes_total=0; line_parts=""
          for k in $kinds; do
            v=$(eval echo "\$CACHE_${k^^}_HIT")
            bytes=$(eval echo "\${CACHE_${k^^}_BYTES-}")
            total=$((total+1))
            if [ "$v" = "true" ] || [ "$v" = "1" ]; then
              hits=$((hits+1)); state=hit
            else
              state=miss
            fi
            # Append size if bytes are provided
            size_part=""
            if [ -n "${bytes}" ] && [ "${bytes}" -gt 0 ] 2>/dev/null; then
              mb=$(awk -v b="${bytes}" 'BEGIN{ printf "%.2f", b/1000000 }')
              size_part=", size ~${mb} MB"
              bytes_total=$((bytes_total + bytes))
            fi
            entry="${k}: ${state}${size_part}"
            if [ -z "$line_parts" ]; then line_parts="$entry"; else line_parts="${line_parts}, $entry"; fi
          done
          ratio=$(awk -v h="$hits" -v t="$total" 'BEGIN{ if (t>0) printf "%.2f", h/t; else printf "n/a" }')
          if [ "$bytes_total" -gt 0 ] 2>/dev/null; then
            mb_total=$(awk -v b="$bytes_total" 'BEGIN{ printf "%.2f", b/1000000 }')
            echo "- Cache: ${hits}/${total} hits (ratio ${ratio}), restored ~${mb_total} MB (${line_parts})" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "- Cache: ${hits}/${total} hits (ratio ${ratio}) (${line_parts})" >> "$GITHUB_STEP_SUMMARY"
          fi
        fi


    - name: Upload observability.json
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: observability
        path: ${{ env.OBS_FILE }}

branding:
  icon: bar-chart-2
  color: green

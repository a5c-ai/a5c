name: "Obs Summary & Artifact"
description: "Aggregate job metrics, write step summary, and upload observability.json"
author: "a5c.ai"
runs:
  using: "composite"
  steps:
    - name: Collect metrics and write summary + file
      id: collect
      shell: bash
      run: |
        set -euo pipefail
        # Defaults (prefer shell defaults over expressions for portability)
        OBS_FILE="${OBS_FILE:-observability.json}"
        JOB_NAME="${JOB_NAME:-${GITHUB_JOB:-}}"
        WORKFLOW_NAME="${WORKFLOW_NAME:-${GITHUB_WORKFLOW:-}}"
        RUN_ID="${RUN_ID:-${GITHUB_RUN_ID:-}}"
        RUN_ATTEMPT="${RUN_ATTEMPT:-${GITHUB_RUN_ATTEMPT:-1}}"
        REPO="${REPO:-${GITHUB_REPOSITORY:-}}"
        SHA="${SHA:-${GITHUB_SHA:-}}"
        BRANCH_REF="${BRANCH_REF:-${GITHUB_REF:-}}"
        CONCLUSION="${CONCLUSION:-}"
        # Optional: caller can pass the workflow run start time; else we'll fallback
        RUN_STARTED_AT="${RUN_STARTED_AT:-}"

        echo "OBS_FILE=${OBS_FILE}" >> "$GITHUB_ENV"

        # Compose JSON (includes coverage, optional cache metrics, started_at/duration)
        node -e "
          const fs = require('fs');
          const env = (k, d = '') => process.env[k] ?? d;
          const startedAtEnv = env('RUN_STARTED_AT') || env('GITHUB_RUN_STARTED_AT') || '';
          const startedAt = startedAtEnv || new Date().toISOString();
          let cov = null;
          try { cov = JSON.parse(fs.readFileSync('coverage/coverage-summary.json', 'utf8')); } catch {}
          // Cache summary from envs
          // Collect cache entries from env keys:
          //   CACHE_<KIND>_HIT=true/false
          //   CACHE_<KIND>_BYTES=36778138
          //   CACHE_<KIND>_KEY=primary-key
          const byKind = new Map();
          for (const [k, v] of Object.entries(process.env)) {
            const m = /^CACHE_([A-Z0-9]+)_(HIT|BYTES|KEY)$/.exec(k);
            if (!m) continue;
            const kind = m[1].toLowerCase();
            const field = m[2];
            const rec = byKind.get(kind) || { kind };
            if (field === 'HIT') rec.hit = String(v).toLowerCase() === 'true' || String(v) === '1';
            else if (field === 'BYTES') {
              const n = Number(v);
              if (!Number.isNaN(n)) rec.bytes = n;
            } else if (field === 'KEY') rec.key = String(v);
            byKind.set(kind, rec);
          }
          const cacheEntries = Array.from(byKind.values());
          const hits = cacheEntries.filter(e => e.hit).length;
          const total = cacheEntries.length;
          const bytes_total = cacheEntries.reduce((a, e) => a + (typeof e.bytes === 'number' ? e.bytes : 0), 0);
          const cache = total ? { entries: cacheEntries, summary: { hits, misses: total - hits, total, bytes_restored_total: bytes_total } } : null;
          const end = new Date();
          const endIso = end.toISOString();
          let durationMs = null;
          try {
            const s = new Date(startedAt);
            if (!isNaN(s.getTime())) durationMs = end.getTime() - s.getTime();
          } catch {}
          const obs = {
            repo: env('GITHUB_REPOSITORY') || env('REPO'),
            workflow: env('GITHUB_WORKFLOW') || env('WORKFLOW_NAME'),
            job: env('JOB_NAME') || env('GITHUB_JOB'),
            run: {
              id: env('GITHUB_RUN_ID') || env('RUN_ID'),
              attempt: Number(env('GITHUB_RUN_ATTEMPT') || env('RUN_ATTEMPT') || '1'),
              sha: env('GITHUB_SHA') || env('SHA'),
              ref: env('GITHUB_REF') || env('BRANCH_REF'),
              actor: env('GITHUB_ACTOR', ''),
              event_name: env('GITHUB_EVENT_NAME', ''),
              conclusion: env('CONCLUSION', ''),
              started_at: startedAt,
              completed_at: endIso,
              duration_ms: durationMs,
            },
            metrics: { coverage: cov, cache },
          };
          process.stdout.write(JSON.stringify(obs, null, 2));
        " > "$OBS_FILE"

        echo "## Observability" >> "$GITHUB_STEP_SUMMARY"
        echo "- Repo: ${REPO}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Workflow: ${WORKFLOW_NAME}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Job: ${JOB_NAME}" >> "$GITHUB_STEP_SUMMARY"
        echo "- Run: ${RUN_ID} (attempt ${RUN_ATTEMPT})" >> "$GITHUB_STEP_SUMMARY"
        if [ -n "${CONCLUSION}" ]; then
          echo "- Conclusion: ${CONCLUSION}" >> "$GITHUB_STEP_SUMMARY"
        fi
        if [ -f coverage/coverage-summary.json ]; then
          LINES=$(node -e "const s=require('fs').readFileSync('coverage/coverage-summary.json','utf8'); const t=JSON.parse(s).total||{}; console.log((t.lines?.pct??0).toFixed(2))")
          FUNCS=$(node -e "const s=require('fs').readFileSync('coverage/coverage-summary.json','utf8'); const t=JSON.parse(s).total||{}; console.log((t.functions?.pct??0).toFixed(2))")
          BRANCHES=$(node -e "const s=require('fs').readFileSync('coverage/coverage-summary.json','utf8'); const t=JSON.parse(s).total||{}; console.log((t.branches?.pct??0).toFixed(2))")
          echo "- Coverage: lines ${LINES}% | funcs ${FUNCS}% | branches ${BRANCHES}%" >> "$GITHUB_STEP_SUMMARY"
        fi
        # Duration line (if computable)
        DUR=$(node -e "try{const o=JSON.parse(require('fs').readFileSync(process.env.OBS_FILE,'utf8')); if(o?.run?.duration_ms!=null){ console.log(o.run.duration_ms) }}catch{}") || true
        if [ -n "${DUR}" ]; then
          echo "- Duration: ${DUR} ms" >> "$GITHUB_STEP_SUMMARY"
        fi
        # Cache summary if envs provided
        kinds=$(env | awk -F= '/^CACHE_[A-Z0-9]+_HIT=/{print $1}' | sed -E 's/^CACHE_([A-Z0-9]+)_HIT.*/\1/; s/.*/\L&/')
        if [ -n "${kinds}" ]; then
          hits=0; total=0; line_parts=""
          for k in $kinds; do
            v=$(eval echo "\$CACHE_${k^^}_HIT")
            bytes=$(eval echo "\${CACHE_${k^^}_BYTES-}")
            total=$((total+1))
            if [ "$v" = "true" ] || [ "$v" = "1" ]; then
              hits=$((hits+1)); state=hit
            else
              state=miss
            fi
            # Append size if bytes are provided
            size_part=""
            if [ -n "${bytes}" ] && [ "${bytes}" -gt 0 ] 2>/dev/null; then
              mb=$(awk -v b="${bytes}" 'BEGIN{ printf "%.2f", b/1000000 }')
              size_part=", size ~${mb} MB"
            fi
            entry="${k}: ${state}${size_part}"
            if [ -z "$line_parts" ]; then line_parts="$entry"; else line_parts="${line_parts}, $entry"; fi
          done
          echo "- Cache: ${hits}/${total} hits (${line_parts})" >> "$GITHUB_STEP_SUMMARY"
        fi

    - name: Upload observability.json
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: observability
        path: ${{ env.OBS_FILE }}

branding:
  icon: bar-chart-2
  color: green

# Predefined CLI command templates for different AI providers
cli:
  custom:
    cli_command: ""
    description: "Custom CLI"
    install: ""
  claude_code:
    cli_command: "cat {{prompt_path}} | claude --mcp-config {{mcp_config}} -p 'fulfill the request' --output-format stream-json --allowedTools Bash,Read,Glob,Grep,Write,MultiEdit,Edit,NotebookRead,NotebookEdit,WebFetch,TodoRead,TodoWrite,WebSearch,Task,Agent,mcp__github,mcp__agent_reporter --dangerously-skip-permissions --verbose --model {{model}}"
    description: "Claude AI via claude-code CLI"
    install: "npm install -g @anthropic-ai/claude-code"
    stdin_enabled: false
  codex:
    cli_command: "cat {{prompt_path}} | codex exec --dangerously-bypass-approvals-and-sandbox -c model={{model}} --output-last-message {{output_last_message_path}}"
    description: "OpenAI models via codex CLI"
    install: "npm install -g @openai/codex@0.31.0"
  jules:
    envs:
      GEMINI_API_KEY: "{{envs.GEMINI_API_KEY}}"
    cli_command: "cat {{prompt_path}} | jules --model {{model}}"
    description: "Google Gemini via official Gemini CLI"
    install: "npm install -g @google/gemini"

profiles:
  openai_codex_gpt5:
    default: true
    cli: codex
    description: "OpenAI via codex CLI"
    model: "gpt-5-2025-08-07"
  azure_codex_gpt5:
    cli: codex
    cli_params: "-c model_provider=azure -c model_providers.azure.name=azure -c model_providers.azure.wire_api=responses -c model_providers.azure.base_url=https://{{envs.AZURE_OPENAI_PROJECT_NAME}}.openai.azure.com/openai -c model_providers.azure.env_key=AZURE_OPENAI_API_KEY -c model_providers.azure.query_params.api-version=2025-04-01-preview"
    model: "gpt-5-codex"
    description: "Azure OpenAI via codex CLI"
  azure_codex_model_router:
    cli: codex
    cli_params: "-c model_provider=azure -c model_providers.azure.name=azure -c model_providers.azure.wire_api=chat -c model_providers.azure.base_url=https://{{envs.AZURE_OPENAI_PROJECT_NAME}}.cognitiveservices.azure.com/openai -c model_providers.azure.env_key=AZURE_OPENAI_API_KEY -c model_providers.azure.query_params.api-version=2025-01-01-preview"
    model: "model-router"
    description: "Azure OpenAI via codex CLI with model-router"
  github_codex_gpt5:
    cli: codex
    cli_params: "-c model_provider=github -c model_providers.github.name=github -c model_providers.github.wire_api=chat -c model_providers.github.base_url=https://models.github.ai/inference -c model_providers.github.env_key=GITHUB_TOKEN -c model_providers.github.query_params.api-version=2025-08-07"
    model: "gpt-5-codex"
    description: "GitHub Models via codex CLI"
  claude_code_sonnet4:
    cli: claude_code
    model: "claude-sonnet-4-20250514"
    description: "Claude Sonnet via codex CLI"
  gemini_jules_25pro:
    cli: jules
    model: "gemini-2.5-pro"
    description: "Google Gemini via official Gemini CLI"
  custom_example1:
    cli: custom
    description: "my custom CLI example"
    cli_command: "cat {{prompt_path}} | mycli run vllm-gpt-oss --model {{model}} --output-last-message {{output_last_message_path}}"
    install: "npm install -g mycli"
    model: "vllm-gpt-oss"
# run command:
# npx -y @a5c-ai/a5c run --in file://./prompt_file.md --out out.json --model gpt-4
# will run the install command for codex: npm install -g @openai/codex and then run the cli_command: codex exec --dangerously-bypass-approvals-and-sandbox -c model=gpt-4 --output-last-message /tmp/agent-output.md --mcps=.a5c/mcps.json
# npx -y @a5c-ai/a5c run --config=.other/config.yml --in github://a5c-ai/a5c/branch/a5c%2Fmain/prompts/dev-prompt.md --mcps=.a5c/mcps.json --out out.json --profile custom_example1 --model vllm-gpt-oss2
# --mcps=.a5c/mcps.json is optional - without it, the default mcps will be .a5c/mcps.json -- should also support the uri formats (github, file, etc.)
# --config=.other/config.yml is optional - without it, the default config path will be .a5c/config.yml -- should also support the uri formats
# --profile custom_example1 is optional - without it, the default profile will be used from the config
# --model vllm-gpt-oss2 is optional - without it, the default model will be used from the profile, with fallback to the model from the cli section
# --in should support the uri formats (github, file, etc.) and should also support stdin (- for stdin , stdin should be the default)
# --out should be optional and should be by default /tmp/agent-output.md
# config.yaml only overrides the sections of predefined.yaml file (this file) - which should be bundled with the package
# uri format and resolution is already implemented in the a5c cli - so resuse the implementation
